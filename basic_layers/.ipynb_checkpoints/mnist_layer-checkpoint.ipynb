{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Model, layers, datasets, optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train.astype(np.float32)/255, x_test.astype(np.float32)/255\n",
    "x_train, x_test = np.expand_dims(x_train, axis=3), np.expand_dims(x_test, axis=3)\n",
    "\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(256)\n",
    "test = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class basic_model(Model):\n",
    "    def __init__(self):\n",
    "        super(basic_model, self).__init__()\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(256, (3, 3), padding=\"same\", input_shape=[28, 28, 1])\n",
    "        self.pool1 = layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.conv2 = layers.Conv2D(128, (3, 3), padding=\"same\")\n",
    "        self.pool2 = layers.MaxPool2D(pool_size=(2,2))\n",
    "        \n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(80, activation='relu')\n",
    "        self.fc2 = layers.Dense(10)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x \n",
    "    \n",
    "class basic_model_2(Model):\n",
    "    def __init__(self):\n",
    "        super(basic_model, self).__init__()\n",
    "        \n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(20))\n",
    "        model.add(activation='relu')\n",
    "        model.add(layers.Dense(10))\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.convert_to_tensor(inputs)\n",
    "\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"basic_model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            multiple                  2560      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            multiple                  295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  501840    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  810       \n",
      "=================================================================\n",
      "Total params: 800,250\n",
      "Trainable params: 800,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_size = 28*28\n",
    "num_epochs = 1000\n",
    "batch_size = 256\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = basic_model()\n",
    "model.build(input_shape=(None, 28, 28, 1))\n",
    "model.summary()\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for step, (x, y) in enumerate(train):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x)\n",
    "            \n",
    "            loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.one_hot(y, depth=10), logits=logits)\n",
    "            \n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        print(\"Epoch[{}/{}], Step[{}/{}],Reconst Loss:{:.4f}\"\n",
    "                  .format(epoch+1, num_epochs, step+1, num_batches, float(reconstruction_loss)))\n",
    "            \n",
    "            \n",
    "    model.save_weights('./my_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
